\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Library of Lighting Models: System Verification and Validation Plan for 
Family of Lighting Models} 
\author{Sasha Soraine}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
October 17, 2019 & 1.0 & Original Draft.\\
\bottomrule
\end{tabularx}

\newpage

\tableofcontents

\listoftables

\listoffigures

\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  \bottomrule
\end{tabular}\\

\wss{symbols, abbreviations or acronyms -- you can simply reference the SRS
  tables, if appropriate}

\newpage

\pagenumbering{arabic}

This document outlines a system validation and verification plan for the 
implementation of a sub-family of lighting models, based on the Commonality 
Analysis for a Family of Lighting Models. First it will cover general 
information about the system, including the particular design qualities the 
system should emphasize and any relevant documentation. Next it will outline 
the verification plans for the commonality analysis/requirements, system 
design, and implementation. It will then outline the software validation plan. 
Finally it will outline a series of representative test cases that are meant to 
test the functional and non-functional requirements, along with a traceability 
matrix mapping the test cases to particular requirements.

\section{General Information}

\subsection{Summary}
This software implements a sub-family of lighting models. The larger family and 
problem analysis is found in \ref{??}. This software aims to take in user 
specifications about the graphical scene (lights, objects, shading model, 
lighting model, and an observer) and render a fully lit and shaded scene. To do 
this is runs calculations using basic optics principles to approximate light 
behaviour in 3D computer graphics.

\subsection{Objectives}
The goal of this testing is to:

\begin{itemize}
	\item Demonstrate adequate usability of the system,
	\item Demonstrate learnability of the system, and
	\item Evaluate the productivity of the system.
\end{itemize}
%
%\wss{State what is intended to be accomplished.  The objective will be around
%  the qualities that are most important for your project.  You might have
%  something like: ``build confidence in the software correctness,''
%  ``demonstrate adequate usability.'' etc.  You won't list all of the 
%qualities,
%  just those that are most important.}

\pagebreak
\subsection{Relevant Documentation}
This section outlines other documentation that is relevant for understanding 
this document.
\begin{table}[h]
	\begin{tabular}{|p{3.5cm}|p{3cm}|p{5cm}|l|}
		\hline
	\textbf{Document Name} & \textbf{Document Type} & \textbf{Document Purpose} 
	& \textbf{Citation} \\
		\hline
		Commonality Analysis of a Family of Lighting Models& Commonality 
		Analysis & Problem domain description, and scoping to a reasonable 
		implementation size through assumptions and requirements. & \\ 
		\hline
	\end{tabular}
\end{table}
%\wss{Reference relevant documentation.  This will definitely include your SRS}

\section{Plan}
This section outlines the verification and validation plans, including any 
techniques or data sets being used in the testing process. It also outlines the 
members of the verification and validations team.
	
\subsection{Verification and Validation Team}
This section lists the members of the verification and validation team. These 
are individuals who contribute to the verification and validation of the system 
and software design. Individuals listed here have specific roles denoting the 
amount of involvement they will be having in the verification and validation 
process. Primary roles are actively working on it; secondary roles view the 
system when major submissions are made; tertiary roles are asked to contribute 
if able, but are under no obligation to participate.

The verification and validation team includes:

\begin{table}[h]
	\begin{tabular}{|l|l|p{9cm}|}
		\hline
		\textbf{Name} & \textbf{Role} & \textbf{Goal} \\
		\hline
		Sasha Soraine & Primary Reviewer& Ensure the verification and 
		validation 
		process runs smoothly.\\
		Peter Michalski & Secondary Reviewer& Ensure the logical consistency of 
		system 
		design and requirements in accordance with feedback role as expert 
		reviewer. \\
		Dr. Spencer Smith & Secondary Reviewer& Ensure reasonable coverage of 
		design 
		considerations and requirements as part of marking these documents. \\
		CAS 741 Students & Tertiary Reviewers& Ensure general consistency in 
		design and 
		requirements coverage in accordance with feedback role as secondary 
		reviewers.\\
		\hline
	\end{tabular}
\end{table}

\pagebreak
\subsection{CA Verification Plan}

We aim to verify the requirements listed in the Commonality Analysis in the 
following ways:

\begin{itemize}
	\item Have expert level users (familiar with graphics programming) do a 
	close read of the commonality analysis to compare it against existing 
	software tools for functionality.
	\item Review and revise requirements based on feedback from Domain Expert 
	and Secondary Reviewer of CA.
	\item Ask Dr. Smith to review the scope to consider whether the 
	implementation scoping and thus listed requirements is inappropriate.
\end{itemize}

\subsection{Design Verification Plan}
The purpose of design verification is to ensure the structure of the code and 
design of the system meets the requirements laid out in \ref{label}.

We will be using the following methods to test the design:

\begin{itemize}
	\item Rubber duck testing,
	\item Expert review,
	\item Task-based peer reviews.
\end{itemize}

The rubber duck testing will be performed by the primary tester (me). The 
rationale is that it should make holes in the design decisions apparent by 
forcing the primary tester to focus on justifying the system. The procedure 
will involve close examination of the code, with a spoken aloud explanation of 
the design decisions.

The expert review will be performed by the secondary reviewers (Peter and Dr. 
Smith). The rationale is that testers familiar with the project should be able 
to verify if the design meets the requirements and constraints. This will be 
done through posting of GitHub issues and feedback in the document.

The task-based peer reviews will be performed by the tertiary testers (CAS 741 
peers). The rationale is that targeted examination of parts of the system are 
easier to perform and will generate better feedback. To divide the tasks, every 
aspect of the system has to fulfil some requirement - the testers will then 
examine whether that component of the system meets that requirement. The 
feedback will be captured via GitHub issues.

\subsection{Implementation Verification Plan}
The purpose of the implementation verification plan is to perform functional 
testing of the components of the system. As such it measures whether the system 
is behaving inline with the requirements documentation, and whether it meets 
its non-functional requirements thresholds.

We will be using the following methods to test the functional implementation:

\begin{itemize}
	\item Rubber duck testing,
	\item Peer reviews,
	\item Expert reviews,
	\item Boundary value testing,
	\item Endurance testing,
	\item Error handling testing.
\end{itemize}

Rubber duck testing, peer reviews, and expert reviews will also be used as 
implementation verification techniques. These will be executed simultaneously 
with the design verification versions, as the close attention paid in that 
setting lends itself to looking for potential implementation errors.

Boundary value testing will outline the expected behaviour of the system at the 
boundaries of variable constraints. This testing ensures that all edge-case 
behaviour has been considered and that system responses are designed for those 
cases.

Error handling testing will outline the expected system behaviour when invalid 
data enters the system. This testing ensures that the system recognizes valid 
data from invalid data and provides appropriate feedback to the user. 
Successful error handling testing will also lead to better usability of the 
system as more feedback on how to correct the system is provided to users.

Endurance testing will outline the system behaviour under repetitive tasks with 
valid input. The purpose of this is to push the system to its load capacity and 
see how it reacts when its output keeps changing. The rationale for this 
testing is to test the reliability of the software.

We will be using the following methods to test the non-functional 
implementation:

\begin{itemize}
	\item Installation testing,
	\item Usability testing.
\end{itemize}

These are carried out through the test cases listed in this document.

These system tests are supplemented by the unit tests listed in \ref{label}. 
This system testing presupposes that the system has passed its unit and 
integration tests, and that the functionality of each part has been verified. 
This assumption allows us to interpret the results of these system tests as 
evaluating the design of the system structure as the sum of its parts.

\subsection{Software Validation Plan}
There are currently no plans to validate the software.
%\wss{If there is any external data that can be used for validation, you should
%  point to it here.  If there are no plans for validation, you should state 
%that
%  here.}

\section{System Test Description}
The following section outlines the test cases to be used for testing the 
functional and non-functional requirements at a system level.

These test cases are divided between the functional and non-functional 
requirements. The functional requirement test cases handle black-box behvaiour 
of the system as it is fed different inputs. The non-functional requirement 
test cases focus on testing the usability of the system as an end-user. 
Therefore it doesn't test the productivity and maintainability based 
non-functional requirements.

\subsection{Tests for Functional Requirements}
The following sections outline test cases for the functional requirements of 
the system.

This section is divided into different testing areas. These are:

\begin{itemize}
	\item Input testing, and
	\item Run-Time testing.
\end{itemize}

The subdivision was made to capture the types of tasks the system would need to 
anticipate at different points in time during use. Input testing is preliminary 
before the system begins to run calculations. Run-time testing is the real-time 
calculations that the system needs to make in response to user input.

There is no explicit output testing. By nature of this system rendering images, 
every functional test implicitly tests the ability to output a file. As such, 
the basic output testing is handled alongside the ``Load a Scene'' tasks.

%\wss{Subsets of the tests may be in related, so this section is divided into
%  different areas.  If there are no identifiable subsets for the tests, this
%  level of document structure can be removed.}
%
%\wss{Include a blurb here to explain why the subsections below
%  cover the requirements.  References to the SRS would be good.}

\subsubsection{Input Testing}

\wss{It would be nice to have a blurb here to explain why the subsections below
  cover the requirements.  References to the SRS would be good.  If a section
  covers tests for input constraints, you should reference the data constraints
  table in the SRS.}
		
\paragraph{Load a Scene}
~\newline
The following test cases all share the same properties:

\begin{itemize}
	\item[] Initial State: No scene loaded.
\end{itemize}

\begin{enumerate}

\item{loadScene-allValid\\}

Control: Automatic
								
Input: \textit{SCENE\_DIR/valid-AllInputs.JSON}
					
Output: \textit{RENDERS\_DIR/render-valid-AllInputs}

Test Case Derivation: Having received a properly formatted and structured JSON 
file containing all inputs for the scene, the system will output a fully 
rendered and lit scene.
					
How test will be performed: System will try to load created test file from 
scene directory.
					
\item{loadScene-validMissingSome\\}

Control: Automatic

Input: \textit{SCENE\_DIR/valid-MissingData.JSON}

Output: Prompt Message: ``File exists, but is missing data. Would you like to 
load the default settings for missing data?", Log message "Error: File exists 
but is missing data."

Test Case Derivation: 

How test will be performed: System will try to load created test file from 
scene directory.

\item{loadScene-fileExistNoData\\}

Control: Automatic
									
Input: \textit{SCENE\_DIR/valid-NoData.JSON}

Output: Prompt Message ``File exists, but is empty. Would you like to load the 
default scene?", Log message "Error: File exists but is empty."

Test Case Derivation: In receiving an empty file, the system should be robust 
enough to acknowledge the specific error and offer to substitute with the 
default scene.

How test will be performed: System will try to load created test file from 
scene directory.

\item{loadScene-invalidInput\\}

Control: Automatic

Input: \textit{SCENE\_DIR/invalid.JSON}

Output: Error Message``File does not contain valid scene data.", Log message 
"Error: Invalid scene data in file: \textit{SCENE\_DIR/invalid.JSON}."

Test Case Derivation: In receiving invalid data, the system should be robust 
enough to acknowledge the specific error and log it in the log file.

How test will be performed: System will try to load created test file from 
scene directory.

\end{enumerate}

\paragraph{Create Default Scene}
~\newline
\begin{enumerate}
	
	\item{createDefault-validMissingData\\}
	
	Control: Automatic

	Initial State: No scene loaded.	System tried to load 
	\textit{SCENE\_DIR/valid-MissingData.JSON} and displayed Prompt Message.

	Input: YES selected at Prompt Message
	
	Output: \textit{RENDERS\_DIR/render-valid-MissingData-defaultsub}
	
	Test Case Derivation: System corrects partially invalid input by 
	substituting missing information with predetermined default values.
	
	How test will be performed: System will fill in empty input with default 
	values.
	
	\item{createDefault-fileExistsNoData\\}
	
	Control: Automatic
	
	Initial State: No scene loaded.	System tried to load 
	\textit{SCENE\_DIR/valid-NoData.JSON} and displayed associated Prompt 
	Message.
	
	Input: YES selected at Prompt Message
	
	Output: \textit{RENDERS\_DIR/render-valid-NoData-defaultsub}
	
	Test Case Derivation: System corrects partially invalid input by 
	substituting missing information with predetermined default values.
	
	How test will be performed: System will fill in empty input with default 
	values.	
	
\end{enumerate}

\subsubsection{Run-Time Tests}
This subset of tests outline scenarios that may happen during the run-time of 
the program. As such it handles changes to the scene and rendering information.

All of these test cases share the following properties:
\begin{itemize}
	\item[] Initial State: A valid scene 
	(\textit{SCENE\_DIR/valid-AllInputs.JSON}) is loaded to the system.
\end{itemize}

\paragraph{Lighting Model Changes}

\begin{enumerate}
	
	\item{lightModel-valid\\}
	
	Control: Automatic
	
	Input: Select different lighting model from dropdown list.
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals based on 
	new lighting models.
	
	Test Case Derivation: After a scene is loaded, the user can only interact 
	with the system through its GUI. Lighting model changes are determined by 
	dropdown list selection.
	
	How test will be performed: System will recalculate luminous intensity of 
	points on objects in the scene using the new model. New luminous intensity 
	information will be sent through the rendering pipeline to output visuals.
	
\end{enumerate}

\paragraph{Shading Model Changes}

\begin{enumerate}
	
	\item{shadingModel-valid\\}
	
	Control: Automatic
	
	Input: Select different shading model from dropdown list.
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals based on 
	new shading models.
	
	Test Case Derivation: After a scene is loaded, the user can only interact 
	with the system through its GUI. Shading model changes are determined by 
	dropdown list selection.
	
	How test will be performed: System will recalculate surface normals of 
	points on objects in the scene using the new model. New surface normal
	information will be sent through the rendering pipeline to output visuals.
	
\end{enumerate}

\paragraph{Object Changes}

\begin{enumerate}
%%Object Material Properties
%Valid changes	
	\item{objMaterialPropChange-valid-ks\\}
	
	Control: Automatic
	
	Input: $k_{s} = 0.5$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{s} = k_{s}\cdot i(p,p_{0}) \cdot \max(0, 
	({L_{r}}\bullet V))^\alpha$. Final colouring of any point in a scene is 
	$(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore changes to the $k_{s}$ 
	impact the specular component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $k_{s}$ the new value. 
	
	\item{objMaterialPropChange-valid-kd\\}
	
	Control: Automatic
	
	Input: $k_{d} = 0.5$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{d} = k_{d}\cdot i(p,p_{0}) \cdot 
	\max(0,(L_{i}\bullet N))$. Final colouring of any point in a scene is 
	$(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore changes to the $k_{d}$ 
	impact the diffuse component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $k_{d}$ the new value. 	

	\item{objMaterialPropChange-valid-ka\\}
	
	Control: Automatic
	
	Input: $k_{a} = 0.5$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{a} = k_{a}\cdot i(p,p_{0})$. Final colouring of 
	any point in a scene is $(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore 
	changes to the $k_{a}$ impact the ambient component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $k_{a}$ the new value. 

	\item{objMaterialPropChange-valid-$\alpha$\\}
	
	Control: Automatic
	
	Input: $\alpha = 2$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{s} = k_{s}\cdot i(p,p_{0}) \cdot \max(0, 
	({L_{r}}\bullet V))^\alpha$. Final colouring of any point in a scene is 
	$(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore changes to the $\alpha$ 
	impact the specular component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $\alpha$ the new value. 

%Invalid
	\item{objMaterialPropChange-invalid-ks\\}
	
	Control: Automatic
	
	Input: $k_{s} = 2$
	
	Output: Error Message ``New value of $k_{s}$ is outside of bounds. Please 
	enter a different value.''. Log message ``Error: tried to assign $k_{s} = 
	2$''. 
	
	Test Case Derivation: $0 \le k_{s} \le 1$; therefore the new assignment is 
	invalid by the constraints.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	attempts to assign $k_{s}$ the new value. Error message is loaded instead. 
	Error is written to log file.
	
	\item{objMaterialPropChange-invalid-kd\\}
	
	Control: Automatic
	
	Input: $k_{d} = 2$
	
	Output: Error Message ``New value of $k_{d}$ is outside of bounds. Please 
	enter a different value.''. Log message ``Error: tried to assign $k_{d} = 
	2$''. 
	
	Test Case Derivation: $0 \le k_{d} \le 1$; therefore the new assignment is 
	invalid by the constraints.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	attempts to assign $k_{d}$ the new value. Error message is loaded instead. 
	Error is written to log file.
	
	\item{objMaterialPropChange-invalid-ka\\}
	
	Control: Automatic
	
	Input: $k_{a} = 2$
	
	Output: Error Message ``New value of $k_{a}$ is outside of bounds. Please 
	enter a different value.''. Log message ``Error: tried to assign $k_{a} = 
	2$''. 
	
	Test Case Derivation: $0 \le k_{a} \le 1$; therefore the new assignment is 
	invalid by the constraints.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	attempts to assign $k_{a}$ the new value. Error message is loaded instead. 
	Error is written to log file.

	\item{objMaterialPropChange-invalid-$\alpha$\\}
	
	Control: Automatic
	
	Input: $\alpha = -2$
	
	Output: Error Message ``New value of $\alpha$ is outside of bounds. Please 
	enter a different value.''. Log message ``Error: tried to assign $\alpha = 
	-2$''. 
	
	Test Case Derivation: $\alpha : \mathbb{Z_{+}}$; therefore the new 
	assignment 
	is invalid by the constraints.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	attempts to assign $\alpha$ the new value. Error message is loaded instead. 
	Error is written to log file.

%Boundary	
	\item{objMaterialPropChange-bound-ks\\}
	
	Control: Automatic
	
	Input: $k_{s} = 1$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{s} = k_{s}\cdot i(p,p_{0}) \cdot \max(0, 
	({L_{r}}\bullet V))^\alpha$. Final colouring of any point in a scene is 
	$(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore changes to the $k_{s}$ 
	impact the specular component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $k_{s}$ the new value. 
	
	\item{objMaterialPropChange-bound-kd\\}
	
	Control: Automatic
	
	Input: $k_{d} = 1$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{d} = k_{d}\cdot i(p,p_{0}) \cdot 
	\max(0,(L_{i}\bullet N))$. Final colouring of any point in a scene is 
	$(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore changes to the $k_{d}$ 
	impact the diffuse component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $k_{d}$ the new value. 	
	
	\item{objMaterialPropChange-bound-ka\\}
	
	Control: Automatic
	
	Input: $k_{a} = 1$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{a} = k_{a}\cdot i(p,p_{0})$. Final colouring of 
	any point in a scene is $(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore 
	changes to the $k_{a}$ impact the ambient component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $k_{a}$ the new value. 
	
	\item{objMaterialPropChange-bound-$\alpha$\\}
	
	Control: Automatic
	
	Input: $\alpha = 0$
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	so that specular reflection uses new value.
	
	Test Case Derivation: $I_{s} = k_{s}\cdot i(p,p_{0}) \cdot \max(0, 
	({L_{r}}\bullet V))^\alpha$. Final colouring of any point in a scene is 
	$(I_{a}+I_{d}+I_{s})\cdot LIGHT\_COLOUR$, therefore changes to the $\alpha$ 
	impact the specular component of the final scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns $\alpha$ the new value.

%%Object Position	
%Valid
	\item{objPosition-valid\\}
	
	Control: Automatic
	
	Input: New Point (2,0,0) for centre of object
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to reflect object movement to coordinate (2,0,0) (including update of 
	lighting as distance from light source is changed).
	
	Test Case Derivation: Lighting is dependent of position of object relative 
	to the light source; therefore movement in position changes the lighting of 
	an object causing all the intensities to be recalculated and the object to 
	be recoloured.

	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (2,0,0). System recalculates 
	intensities and recolours moved object.
	
%Invalid	
	\item{objPosition-invalid-outBounds\\}
	
	Control: Automatic
	
	Input: New Point (11,0,0) for centre of object
	
	Output: Error Message ``The centre of this object is outside of the room. 
	It cannot be rendered. Please enter a different location for this 
	object.''. Log message ``Error: Tried to move centre of object to (11,0,0).
	
	Test Case Derivation: Scene size is defined to be (SCENE\_HEIGHT, 
	SCENE\_WIDTH, SCENE\_DEPTH); if any component of the object's position is 
	greater than any component of the scene size then the object is out of 
	bounds. Out of bounds objects cannot be lit or rendered.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (11,0,0). System throws an error.
	
	\item{objPosition-invalid-onLight\\}
	
	Control: Automatic
	
	Input: New Point (5,5,5) for centre of object
	
	Output: Error Message ``The centre of this object intersects the light 
	source.	It cannot be rendered. Please enter a different location for this 
	object.''. Log message ``Error: Tried to move centre of object to light 
	source position, (5,5,5)''.
	
	Test Case Derivation: As per the requirement (\ref) objects cannot be on 
	top of the light source. This would create a design issue of whether the 
	opaque object would be blocking the light. To circumvent this, we impose 
	that they cannot have their centres at the same position.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (5,5,5). System throws an error.

	\item{objPosition-invalid-onObserver\\}
	
	Control: Automatic
	
	Input: New Point (0,0,0) for centre of object
	
	Output: Error Message ``The centre of this object intersects the observer.	
	It cannot be rendered. Please enter a different location for this 
	object.''. Log message ``Error: Tried to move centre of object to observer 
	position, (0,0,0)''.
	
	Test Case Derivation: As per the requirement (\ref) objects cannot be on 
	top of the observer. This would create a design issue of whether the 
	opaque object would be blocking the view, and how it would be lit. To 
	circumvent this, we impose that they cannot have their centres at the same 
	position.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (0,0,0). System throws an error.
	
%Boundary		
	\item{objPosition-valid-edgeOfRoom\\}
	
	Control: Automatic
	
	Input: New Point (0,10,0) for centre of object
	
	Output: Error Message ``Parts of this object are outside of the scene size. 
	Please move this object and re-render the scene.''. Log Message ``Error: 
	Object partially outside of room.''
	
	Test Case Derivation: Constraints on object position said $0 \ll 
	x \le SIZE\_HEIGHT$, which means that the centre is on the wall of the 
	scene. This means part of the object would be rendered outside the scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (0,10,0). System throws an error.

	\item{objPosition-valid-betweenLightAndViewer\\}
	
	Control: Automatic
	
	Input: New Point (2,2,2) for centre of object
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to reflect object movement to coordinate (2,2,2) (including update of 
	lighting as distance from light source is changed).
	
	Test Case Derivation: Lighting is dependent of position of object relative 
	to the light source; therefore movement in position changes the lighting of 
	an object causing all the intensities to be recalculated and the object to 
	be recoloured. When an object is between the light and the viewer its faces 
	should be dark as they're not being lit.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (2,2,2). System recalculates 
	intensities and recolours moved object.	
	
	\item{objPosition-valid-besideLight\\}
	
	Control: Automatic
	
	Input: New Point (5,3,0) for centre of object
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to reflect object movement to coordinate (5,3,0) (including update of 
	lighting as distance from light source is changed).
	
	Test Case Derivation: Lighting is dependent of position of object relative 
	to the light source; therefore movement in position changes the lighting of 
	an object causing all the intensities to be recalculated and the object to 
	be recoloured. When an object is beside a light source it is highly 
	illuminated making it very bright.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (5,3,0). System recalculates 
	intensities and recolours moved object.			

%%Object Colour
	\item{objColour-valid-base\\}
	
	Control: Automatic
	
	Input: New (r,g,b) value for BASE\_COLOUR picked from GUI picker = 
	(10,255,50).
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to reflect the new base colour for the object. All diffuse terms need to be 
	recalculated.
	
	Test Case Derivation: The intensity of the BASE\_COLOUR at a point is part 
	of the diffuse model calculation. Change the BASE\_COLOUR requires 
	recalculating all of the intensity values with this new (r,g,b) information.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new r,g,b to (10,255,50). System recalculates 
	intensities and recolours object.			

	\item{objColour-valid-specular\\}
	
	Control: Automatic
	
	Input: New (r,g,b) value for SPECULAR\_COLOUR picked from GUI picker = 
	(10,255,50).
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to reflect the new base colour for the object. All diffuse terms need to be 
	recalculated.
	
	Test Case Derivation: The intensity of the SPECULAR\_COLOUR at a point is 
	part of the specular component calculation. Change the SPECULAR\_COLOUR 
	requires recalculating all of the intensity values with this new (r,g,b) 
	information.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new r,g,b to (10,255,50). System recalculates 
	intensities and recolours object.	
	
	\item{objShape-valid\\}
	
	Control: Automatic
	
	Input: New shape selection from dropdown list: torus.
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to replace the sphere with a torus. All normals have changed, so all 
	intensities need to be recalculated.
	
	Test Case Derivation: Different shapes have different normals, and so 
	different ways of reflecting. The models need  to be sure to work with not 
	just a sphere, but other objects as well.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new object shape. System recalculates 
	intensities and recolours new object.
	
		
\end{enumerate}

\paragraph{Light Changes}

\begin{enumerate}
%%Light Positions
%Valid
	\item{lightPos-valid\\}
	
	Control: Automatic
	
	Input: New Point (2,0,0) for centre of light source
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to reflect light source movement to coordinate (2,0,0) (including update of 
	lighting as distance from light source is changed).
	
	Test Case Derivation: Lighting is dependent of position of object relative 
	to the light source; therefore movement in light source position changes 
	the lighting of objects causing all the intensities to be recalculated and 
	the object to be recoloured.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (2,0,0). System recalculates 
	intensities and recolours moved object.
	
%Invalid	
	\item{lightPos-invalid-outBounds\\}
	
	Control: Automatic
	
	Input: New Point (11,0,0) for centre of light
	
	Output: Error Message ``This light source is outside of the room. It cannot 
	be rendered. Please enter a different location for this object.''. Log 
	message ``Error: Tried to move light source to (11,0,0).
	
	Test Case Derivation: Scene size is defined to be (SCENE\_HEIGHT, 
	SCENE\_WIDTH, SCENE\_DEPTH); if any component of the light source's 
	position is greater than any component of the scene size then the light 
	source is out of bounds. Out of bounds light sources cannot light the scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (11,0,0). System throws an error.
	
	\item{lightPos-invalid-onObj\\}
	
	Same as \textit{objPosition-invalid-onLight}.
	
	\item{lightPos-invalid-onObserver\\}
	
	Control: Automatic
	
	Input: New Point (0,0,0) for centre of light source.
	
	Output: Error Message ``The centre of this light source intersects the 
	observer. It cannot be rendered. Please enter a different location for this 
	object.''. Log message ``Error: Tried to move light source to observer 
	position, (0,0,0)''.
	
	Test Case Derivation: As per the requirement (\ref) light sources cannot be 
	on top of the observer. We impose that they cannot have their centres at 
	the same position.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (0,0,0). System throws an error.

%Boundary	
	\item{test-id2\\}Change Light Position -boundary
	
	Control: Automatic
	
	Input: New Point (0,10,0) for centre of light source.
	
	Output: Error Message ``Parts of this light source are outside of the scene 
	size. Please move the light and re-render the scene.''. Log Message 
	``Error: Light source partially outside of room.''
	
	Test Case Derivation: Constraints on light position said $0 \ll 
	x \le SIZE\_HEIGHT$, which means that the centre is on the wall of the 
	scene. This means part of the light would be rendered outside the scene.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new position to (0,10,0). System throws an error.
	
	\item{lightPos-valid-besideObject\\}
	
	Same as \textit{objPosition-valid-besideLight}.
	
	\item{lightPos-valid-behindObject\\}
		
	Same as \textit{objPosition-valid-betweenLightAndViewer}.

%%Light Colour Change
	\item{lightColour-valid\\}
	
	Control: Automatic
	
	Input: New (r,g,b) value for LIGHT\_COLOUR picked from GUI picker = 
	(10,255,50).
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to reflect the new light colour. All intensities need to be 
	recalculated.
	
	Test Case Derivation: The intensity of the LIGHT\_COLOUR at a point is part 
	of all lighting model calculations. Changes to the LIGHT\_COLOUR requires 
	recalculating all of the intensity values with this new (r,g,b) information.
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new r,g,b to (10,255,50). System recalculates 
	intensities and recolours object.		


%%Light Type Change	
	\item{lightShape-valid\\}
	
	Control: Automatic
	
	Input: New light type selection from dropdown list: directional.
	
	Output: \textit{RENDERS\_DIR/render-valid-AllInputs} with visuals changed 
	to replace the point light with a directional light. Some incidence rays 
	have changed, so all intensities need to be recalculated.
	
	Test Case Derivation: Different types of light project light rays 
	differently. As such the system needs to adapt to the changing type of 
	lights available
	
	How test will be performed: Valid scene is loaded. Testing framework 
	automatically assigns new light type. System recalculates 
	intensities and recolours new object.
	
\end{enumerate}

\subsection{Tests for Nonfunctional Requirements}
The following section outlines the test cases for the non-functional 
requirements of the system. In particular these tests focus on the usability of 
the system, encompassing aspects like ease of installation and learnability.
%
%\wss{The nonfunctional requirements for accuracy will likely just reference the
%  appropriate functional tests from above.  The test cases should mention
%  reporting the relative error for these tests.}
%
%\wss{Tests related to usability could include conducting a usability test and
%  survey.}

\subsubsection{Usability}
		
\paragraph{Ease of Installation}
The following test cases focuses on assessing the ease of installation of the 
system. It would be unrealistic to test all potential install environments; 
however due to this being implemented in Unity, the installation environments 
of this system are limited to those that Unity can run on.

For this type of testing we are testing to pass, not testing to fail - i.e. we 
want all of these test cases to pass. We are not concerned with cases of 
invalid input, since that would just mean not installing our software. We let 
the Unity error handling inform the user if the installation is unsuccessful.

\begin{enumerate}

\item{install-clean-modern-win\\}

Type: Manual
					
Initial State: Clean installation of Unity version CURRENT\_VERSION on a 
Windows 10 machine.
					
Input/Condition: Install system package.
					
Output/Result: Installation of Unity version CURRENT\_VERSION on a 
Windows 10 machine with our system installed.
					
How test will be performed: 

\item{install-clean-modern-mac\\}

Type: Manual

Initial State: Clean installation of Unity version CURRENT\_VERSION on a Mac OS 
machine.

Input/Condition: Install system package.

Output/Result: Installation of Unity version CURRENT\_VERSION on a 
MacOS machine with our system installed.

How test will be performed: 
					
\item{install-clean-previous-windows\\}

Type: Manual

Initial State: Clean installation of Unity version PREVIOUS\_VERSION on a 
Windows 10 machine.

Input/Condition: Install system package.

Output/Result: Installation of Unity version PREVIOUS\_VERSION on a 
Windows 10 machine with our system installed.

How test will be performed: 

\item{install-clean-previous-mac\\}

Type: Manual

Initial State: Clean installation of Unity version PREVIOUS\_VERSION on a Mac 
OS machine.

Input/Condition: Install system package.

Output/Result: Installation of Unity version PREVIOUS\_VERSION on a 
MacOS machine with our system installed.

How test will be performed: 

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Traceability Between Test Cases and Requirements}

\wss{Provide a table that shows which test cases are supporting which
  requirements.}
				
\bibliographystyle{plainnat}

\bibliography{SRS}

\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

\wss{This is a section that would be appropriate for some projects.}

\end{document}